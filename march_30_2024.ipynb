{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googletran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "latency refers to the time delay between when an event is triggered and when it is observed or acted upon. In the context of speech recognition, latency specifically refers to the time it takes for the system to process an audio input and produce a corresponding transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy refers to how well the transcribed text matches the actual spoken words. It measures the correctness of the transcription compared to a reference or ground truth.\n",
    "\n",
    "Accuracy is often evaluated using metrics such as Word Error Rate (WER), Character Error Rate (CER), or simply by comparing the recognized text to a known ground truth.\n",
    "\n",
    "For example, if the ground truth for a given audio segment is \"hello world\" and the speech recognition system transcribes it as \"hallo world\", then the accuracy would be affected, as one word was recognized incorrectly.\n",
    "\n",
    "High accuracy is desirable in speech recognition systems as it indicates the system's ability to understand and transcribe spoken language correctly, which is crucial for various applications such as dictation, virtual assistants, and transcription service\n",
    "\n",
    "s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual code\n",
    "\n",
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import keyboard                         \n",
    "\n",
    "model = Model(r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk models\\vosk-model-en-in-0.5\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "while True:\n",
    "    data = stream.read(4096)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = recognizer.Result()\n",
    "        print(result)\n",
    "    if keyboard.is_pressed('e'):  # check if 'q' is pressed\n",
    "        break                     # exit the loop if 'q' is pressed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"let's let's go to\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"adam\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"among\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"i think\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"let's watch\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"we have enough\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"just days after a nun\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"aspca\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"yeah while commented that today's dumpster\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"just running on for our income experiments\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"yeah once i come back\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"yeah the air\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"yet here it was taken left them on\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"yeah that felt on it\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"tired\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"beyond\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"if\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"yeah a fair price the year that will suffering\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"titan for an end to inject\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"means it will take just running around\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"yeah i think heavily come now also think it's it's just not editing\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"called on mayor\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"us has carried it off\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"hello\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"that's so let's watch\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"wherever you cool\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"yeah\"\n",
      "}\n",
      "Stopping...\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import keyboard\n",
    "\n",
    "def main():\n",
    "    model_path = r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk models\\vosk-model-en-in-0.5\"\n",
    "    model = Model(model_path)\n",
    "    recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "    mic = pyaudio.PyAudio()\n",
    "    stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=8192)\n",
    "    stream.start_stream()\n",
    "\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(4096)\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                result = recognizer.Result()\n",
    "                print(result)\n",
    "            if keyboard.is_pressed('e'):  # check if 'e' is pressed\n",
    "                break  # exit the loop if 'e' is pressed\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        print(\"Stopping...\")\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        mic.terminate()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'speak container hello'}\n",
      "Transcription Latency: 3.6340041160583496 seconds\n",
      "{'text': 'for hello'}\n",
      "Transcription Latency: 2.603429079055786 seconds\n",
      "{'text': 'going hello'}\n",
      "Transcription Latency: 0.9453418254852295 seconds\n",
      "{'text': \"i'm going to a way let's watch together\"}\n",
      "Transcription Latency: 5.6273486614227295 seconds\n",
      "{'text': \"how about tested as let's go\"}\n",
      "Transcription Latency: 4.117973804473877 seconds\n",
      "{'text': 'you can both go to russia and however they studied go to school'}\n",
      "Transcription Latency: 8.166841983795166 seconds\n",
      "{'text': \"let's watch a movie\"}\n",
      "Transcription Latency: 3.588095188140869 seconds\n",
      "{'text': 'okay'}\n",
      "Transcription Latency: 4.616008996963501 seconds\n"
     ]
    }
   ],
   "source": [
    "#for latency\n",
    "\n",
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import keyboard\n",
    "import json\n",
    "import time  \n",
    "\n",
    "model = Model(r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk models\\vosk-model-small-en-in-0.4\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "total_words = 0  \n",
    "correct_words = 0  \n",
    "start_time = time.time()  # start time for measuring transcription latency\n",
    "\n",
    "while True:\n",
    "    data = stream.read(4096)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = json.loads(recognizer.Result())  # convert JSON string to dictionary\n",
    "        print(result)\n",
    "        \n",
    "        # increment total words counter\n",
    "        total_words += 1\n",
    "        \n",
    "        # calculate accuracy\n",
    "        result_text = result[\"text\"]\n",
    "        \n",
    "        ground_truth_text = \"\"  \n",
    "        for word in result_text.split():\n",
    "            if word in ground_truth_text:\n",
    "                correct_words += 1\n",
    "        \n",
    "        # calculate transcription latency\n",
    "        end_time = time.time()\n",
    "        latency = end_time - start_time\n",
    "        print(\"Transcription Latency:\", latency, \"seconds\")\n",
    "        \n",
    "        # reset start time for next measurement\n",
    "        start_time = end_time\n",
    "    \n",
    "    if keyboard.is_pressed('e'):  # check if 'e' is pressed\n",
    "        break  # exit the loop if 'e' is pressed\n",
    "\n",
    "\n",
    "# clean up resources\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "mic.terminate()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " when there's no speech input, the system is still processing and providing empty transcriptions, leading to increased latency. To reduce latency, you can implement a mechanism to skip processing when there's no meaningful audio input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized Text: where are you going\n",
      "Accuracy: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "#for checking the accuracy , for given ground truth word and word its predicted\n",
    "\n",
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import json\n",
    "\n",
    "# lad the Vosk model\n",
    "model = Model(r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk models\\vosk-model-en-in-0.5\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "# opening the pen microphone stream\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "\n",
    "ground_truth_text = \"where are you going\"   #we can give our word\n",
    "\n",
    "total_words = 0\n",
    "correct_words = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data = stream.read(4096)\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            recognized_text = result.get(\"text\", \"\").lower()  # convert recognized text to lowercase\n",
    "            print(\"Recognized Text:\", recognized_text)\n",
    "            \n",
    "            # now calculate accuracy\n",
    "            total_words += len(ground_truth_text.split())\n",
    "            for word in recognized_text.split():\n",
    "                if word in ground_truth_text.lower().split():\n",
    "                    correct_words += 1\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    mic.terminate()\n",
    "\n",
    "# calculate accuracy percentage\n",
    "accuracy_percentage = (correct_words / total_words) * 100 if total_words > 0 else 0\n",
    "print(\"Accuracy:\", accuracy_percentage, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi: {\n",
      "  \"text\" : \"hello\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"हैलो\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"hello\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"हैलो\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"hello\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"हैलो\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"what are you doing\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"आप क्या कर रहे हैं\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"what are you doing\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"आप क्या कर रहे हैं\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "English: {\n",
      "  \"मूलपाठ\" : \"\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "English: {\n",
      "  \"मूलपाठ\" : \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#hindi to english meaning words\n",
    "\n",
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import keyboard\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "model = Model(r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk models\\vosk-model-small-en-in-0.4\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=1024)  # adjust buffer size here\n",
    "stream.start_stream()\n",
    "\n",
    "while True:\n",
    "    data = stream.read(1024)  # adjust read size here\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = recognizer.Result()\n",
    "        hindi_text = result.strip()  # stripping any leading/trailing spaces\n",
    "        if hindi_text:\n",
    "            translation = translator.translate(hindi_text, src='en', dest='hi')\n",
    "            print(\"Hindi:\", hindi_text)\n",
    "            print(\"English:\", translation.text)\n",
    "    if keyboard.is_pressed('e'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi: {\n",
      "  \"text\" : \"hello\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"हैलो\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"hello\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"हैलो\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"hello\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"हैलो\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recognizer\u001b[38;5;241m.\u001b[39mAcceptWaveform(data):\n\u001b[0;32m     21\u001b[0m         result \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mResult()\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import keyboard\n",
    "from googletrans import Translator\n",
    "import time\n",
    "\n",
    "translator = Translator()\n",
    "model = Model(r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk models\\vosk-model-small-en-in-0.4\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=1024)\n",
    "stream.start_stream()\n",
    "\n",
    "speaking = False\n",
    "start_time = None\n",
    "\n",
    "while True:\n",
    "    data = stream.read(1024)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = recognizer.Result()\n",
    "        hindi_text = result.strip()  # Stripping any leading/trailing spaces\n",
    "        if hindi_text:\n",
    "            translation = translator.translate(hindi_text, src='en', dest='hi')\n",
    "            print(\"Hindi:\", hindi_text)\n",
    "            print(\"English:\", translation.text)\n",
    "            \n",
    "            if not speaking:  # Start measuring latency when speaking starts\n",
    "                start_time = time.time()\n",
    "                speaking = True\n",
    "    \n",
    "    # Check for speaking end (no audio input)\n",
    "    if speaking and sum(abs(x) for x in data) < 500:\n",
    "        end_time = time.time()\n",
    "        latency = end_time - start_time\n",
    "        print(\"Latency:\", latency)\n",
    "        speaking = False\n",
    "\n",
    "    if keyboard.is_pressed('e'):\n",
    "        break\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "mic.terminate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
