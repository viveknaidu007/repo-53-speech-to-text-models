{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vosk\n",
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model , KaldiRecognizer\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\" : \"तुम्हारा नाम क्या है\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"हाँ तो खाना का है\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"अरे हमारे पैसा डाला भाई जल्दी\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"तो जल्द वापस पर कंचन को\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"बस से लेकर गए\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m stream\u001b[38;5;241m.\u001b[39mstart_stream()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recognizer\u001b[38;5;241m.\u001b[39mAcceptWaveform(data):\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28mprint\u001b[39m(recognizer\u001b[38;5;241m.\u001b[39mResult())\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\genai\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hindi model\n",
    "\n",
    "model = Model(\".\\\\vosk\\\\vosk-model-small-hi-0.22\")\n",
    "\n",
    "\n",
    "recognizer = KaldiRecognizer(model , 16000) #16000 Hz  #16000 is deafault sampel rate of data , it slike 16000 samples captured per second \n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000,channels=1,format=pyaudio.paInt16,input=True,frames_per_buffer=8192)\n",
    "\n",
    "'''\n",
    "1 channel: Mono audio, where all audio signals are combined into a single channel.\n",
    "2 channels: Stereo audio, where there are separate channels for the left and right audio \n",
    "means it captures a single audio channel\n",
    "'''\n",
    "#\n",
    "'''\n",
    "pyaudio.paInt16 represents 16-bit signed integers, which is a common format for audio data.\n",
    " It means that each audio sample is a 16-bit integer, which allows for a wide range of amplitudes\n",
    " (from -32,768 to 32,767).\n",
    "'''\n",
    "#\n",
    "'''\n",
    "input=True indicates that the stream will be used for audio input,\n",
    " meaning it will capture audio from an input source such as a microphone.\n",
    "\n",
    "'''\n",
    "#\n",
    "'''\n",
    "number of audio frames (chunks of audio data) per buffer\n",
    "frames_per_buffer=8192 indicates that each buffer will contain 8192 audio frames\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "stream.start_stream()\n",
    "\n",
    "while True:\n",
    "    data = stream.read(4096)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        print(recognizer.Result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\" : \"what are you\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"a fast a fire where to go\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"a high water a day\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"hello\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"hi my name is rick\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"it's been from of didn't ah what ah what still a high school\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"my my name is the rape\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"i am from mandarin this\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m stream\u001b[38;5;241m.\u001b[39mstart_stream()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recognizer\u001b[38;5;241m.\u001b[39mAcceptWaveform(data):\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(recognizer\u001b[38;5;241m.\u001b[39mResult())\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\genai\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#its an english model\n",
    "\n",
    "model = Model(\".\\\\vosk\\\\vosk-model-small-en-us-0.15\")\n",
    "\n",
    "\n",
    "recognizer = KaldiRecognizer(model , 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000,channels=1,format=pyaudio.paInt16,input=True,frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "while True:\n",
    "    data = stream.read(4096)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        print(recognizer.Result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\" : \"te veo no remo durmió\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"la vez es como nácar dicha outlets en tío lee for nueva york lea con perennes engloba y el prudente neo de hermosura en kansas\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"las\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"net seguí venga de frank ocean es gran esfuerzo y de tiro\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"los good red viven eviten saquen\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"ah\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m stream\u001b[38;5;241m.\u001b[39mstart_stream()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recognizer\u001b[38;5;241m.\u001b[39mAcceptWaveform(data):\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(recognizer\u001b[38;5;241m.\u001b[39mResult())\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\genai\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for spanish language\n",
    "\n",
    "\n",
    "#its an english model\n",
    "\n",
    "model = Model(r\"C:\\Users\\poppo\\Desktop\\github ai\\end to end by vivek\\repo-53-speech-to-text-models\\vosk\\vosk-model-small-es-0.42\")\n",
    "\n",
    "\n",
    "recognizer = KaldiRecognizer(model , 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000,channels=1,format=pyaudio.paInt16,input=True,frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "while True:\n",
    "    data = stream.read(4096)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        print(recognizer.Result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\" : \"bon\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"très bonne fort mais le fait staline au cafe pleine des feux du scot exclusivement s\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"non pas de toi\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"l'accès à tous\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"a toi viens à peine d'apprendre taxi la défense bandeau en place\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m stream\u001b[38;5;241m.\u001b[39mstart_stream()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recognizer\u001b[38;5;241m.\u001b[39mAcceptWaveform(data):\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(recognizer\u001b[38;5;241m.\u001b[39mResult())\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\genai\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for french language\n",
    "\n",
    "\n",
    "#its an english model\n",
    "\n",
    "model = Model(r\"C:\\Users\\poppo\\Desktop\\github ai\\end to end by vivek\\repo-53-speech-to-text-models\\vosk\\vosk-model-small-fr-0.22\")\n",
    "\n",
    "\n",
    "recognizer = KaldiRecognizer(model , 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000,channels=1,format=pyaudio.paInt16,input=True,frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "while True:\n",
    "    data = stream.read(4096)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        print(recognizer.Result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Importing Necessary Libraries:\n",
    "        from vosk import Model, KaldiRecognizer: This line imports the Model and KaldiRecognizer classes from the Vosk library.\n",
    "        import pyaudio: This imports the PyAudio library, which is used for audio input and output operations.\n",
    "\n",
    "    Initializing the Vosk Model:\n",
    "        model = Model(\".\\\\vosk\\\\vosk-model-small-hi-0.22\"): This line initializes the Vosk model with a pre-trained Hindi model. The path provided points to the location of the pre-trained model file.\n",
    "\n",
    "    Initializing the Recognizer:\n",
    "        recognizer = KaldiRecognizer(model, 16000): Here, a KaldiRecognizer object is created using the initialized Vosk model. It specifies the sample rate of the audio data, which is set to 16000 samples per second.\n",
    "\n",
    "    Initializing PyAudio and Audio Stream:\n",
    "        mic = pyaudio.PyAudio(): This line initializes PyAudio, which is used to manage audio input and output.\n",
    "        stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=8192): Here, an audio stream is opened for recording. It specifies parameters such as sample rate (16000 Hz), number of channels (1 for mono), audio format (16-bit integer), and buffer size.\n",
    "\n",
    "    Starting the Audio Stream:\n",
    "        stream.start_stream(): This line starts the audio stream, allowing data to be recorded from the microphone.\n",
    "\n",
    "    Speech Recognition Loop:\n",
    "        while True:: This creates an infinite loop to continuously capture audio data and perform speech recognition.\n",
    "\n",
    "    Recording and Processing Audio Data:\n",
    "        data = stream.read(4096): Inside the loop, audio data is read from the stream in chunks of 4096 frames.\n",
    "        if recognizer.AcceptWaveform(data):: This condition checks if the recognizer can accept the waveform data chunk.\n",
    "\n",
    "    Performing Speech Recognition:\n",
    "        print(recognizer.Result()): If the recognizer accepts the waveform data, the Result() function is called to obtain the recognized text from the audio chunk, and it's printed to the console.\n",
    "\n",
    "    Background Process:\n",
    "        Behind the scenes, the Vosk library uses a pre-trained deep learning model (acoustic model) to convert the audio waveform into text. This model has been trained on a large dataset of speech samples. The recognizer then matches the incoming audio data with the trained model to recognize spoken words and convert them into text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
