{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained model from vosk hindi language\n",
    "\n",
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import keyboard                         \n",
    "\n",
    "model = Model(r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk-model-hi-0.22\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "while True:\n",
    "    data = stream.read(4096)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = recognizer.Result()\n",
    "        print(result)\n",
    "    if keyboard.is_pressed('e'):  # check if 'q' is pressed\n",
    "        break                     # exit the loop if 'q' is pressed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "English: {\n",
      "  \"मूलपाठ\" : \"\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "English: {\n",
      "  \"मूलपाठ\" : \"\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "English: {\n",
      "  \"मूलपाठ\" : \"\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "English: {\n",
      "  \"मूलपाठ\" : \"\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"when that firm\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"जब वह फर्म\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "English: {\n",
      "  \"मूलपाठ\" : \"\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "English: {\n",
      "  \"मूलपाठ\" : \"\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "English: {\n",
      "  \"मूलपाठ\" : \"\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"pantheon there were running\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"पैंथियन वहाँ चल रहे थे\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"okay no no issues\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"ठीक नहीं कोई समस्या नहीं है\"\n",
      "}\n",
      "Hindi: {\n",
      "  \"text\" : \"so you you try to get it out\"\n",
      "}\n",
      "English: {\n",
      "  \"पाठ\": \"तो आप इसे बाहर निकालने की कोशिश करते हैं\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m stream\u001b[38;5;241m.\u001b[39mstart_stream()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust read size here\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recognizer\u001b[38;5;241m.\u001b[39mAcceptWaveform(data):\n\u001b[0;32m     19\u001b[0m         result \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mResult()\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\genai\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hindi to english meaning words\n",
    "\n",
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import keyboard\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "model = Model(r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk models\\vosk-model-small-en-in-0.4\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=1024)  # Adjust buffer size here\n",
    "stream.start_stream()\n",
    "\n",
    "while True:\n",
    "    data = stream.read(1024)  # Adjust read size here\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = recognizer.Result()\n",
    "        hindi_text = result.strip()  # stripping any leading/trailing spaces\n",
    "        if hindi_text:\n",
    "            translation = translator.translate(hindi_text, src='en', dest='hi')\n",
    "            print(\"Hindi:\", hindi_text)\n",
    "            print(\"English:\", translation.text)\n",
    "    if keyboard.is_pressed('e'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import keyboard\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "model = Model(\"vosk-model-small-hi-0.22\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=1024)  # Adjust buffer size here\n",
    "stream.start_stream()\n",
    "\n",
    "while True:\n",
    "    data = stream.read(1024)  # Adjust read size here\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = recognizer.Result()\n",
    "        hindi_text = result.strip()  # Stripping any leading/trailing spaces\n",
    "        if hindi_text:\n",
    "            translation = translator.translate(hindi_text, src='hi', dest='en')\n",
    "            print(\"English:\", translation.text)\n",
    "    if keyboard.is_pressed('e'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import keyboard\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import time\n",
    "\n",
    "model = Model(\"vosk-model-small-hi-0.22\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(rate=16000, channels=1, format=pyaudio.paInt16, input=True, frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "start_time = time.time()  # record start time\n",
    "\n",
    "while True:\n",
    "    data = stream.read(4096)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = recognizer.Result()\n",
    "        print(result)\n",
    "        end_time = time.time()  # record end time when transcription is done\n",
    "        time_taken = end_time - start_time  # calculate time taken\n",
    "        print(\"Time taken to transcribe:\", time_taken, \"seconds\")\n",
    "        break  # exit the loop after printing time taken\n",
    "    if keyboard.is_pressed('e'):  # check if e is pressed\n",
    "        break  # exit the loop if 'e' is pressed\n",
    "\n",
    "stream.stop_stream()\n",
    "mic.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "kaldi_script_path = \"finetune_tdnn_1a.sh\"\n",
    "\n",
    "#Kaldi script using subprocess\n",
    "try:\n",
    "    subprocess.run([\"bash\", kaldi_script_path], check=True)\n",
    "    print(\"Kaldi script executed successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error executing Kaldi script: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "hindi_dir = \"Hindi\"\n",
    "\n",
    "\n",
    "files = os.listdir(hindi_dir)\n",
    "\n",
    "\n",
    "num_files = len(files)\n",
    "\n",
    "print(f\"Number of files in '{hindi_dir}': {num_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def speech_to_text():\n",
    "    # Initialize the recognizer\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Use the microphone as the audio source\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "\n",
    "        # Adjust for ambient noise\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "        # Listen for the user's input\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        print(\"Recognizing...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
