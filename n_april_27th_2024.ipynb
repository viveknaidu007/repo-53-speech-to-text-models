{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognized: hello this is rebecca else from mom that of others a hafta a busy graduation and such a warmer your inner city in china google and bonding (Latency: 2.72 seconds)\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecognized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Latency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatency\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 59\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# duration in seconds\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mcapture_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# recognize the captured audio\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     text, latency \u001b[38;5;241m=\u001b[39m recognize_audio(audio_data)\n",
      "Cell \u001b[1;32mIn[15], line 46\u001b[0m, in \u001b[0;36mcapture_audio\u001b[1;34m(duration, rate, chunk)\u001b[0m\n\u001b[0;32m     44\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(rate \u001b[38;5;241m/\u001b[39m chunk \u001b[38;5;241m*\u001b[39m duration)):\n\u001b[1;32m---> 46\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m     49\u001b[0m stream\u001b[38;5;241m.\u001b[39mstop_stream()\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\vosk\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#without cuda:\n",
    "\n",
    "#for english\n",
    "\n",
    "#running continue loop of model\n",
    "#with latency\n",
    "\n",
    "\n",
    "import os\n",
    "import pyaudio\n",
    "import vosk\n",
    "import json\n",
    "import time\n",
    "\n",
    "# set the path to the Vosk model\n",
    "MODEL_PATH = r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk models\\vosk-model-en-in-0.5\"\n",
    "\n",
    "# initialize the Vosk model\n",
    "vosk.SetLogLevel(-1)\n",
    "model = vosk.Model(MODEL_PATH)\n",
    "rec = vosk.KaldiRecognizer(model, 16000)\n",
    "\n",
    "# ffunction to recognize speech from audio\n",
    "def recognize_audio(audio):\n",
    "    start_time = time.time()  # Record start time\n",
    "\n",
    "    rec.AcceptWaveform(audio)\n",
    "\n",
    "    # getting the recognized text\n",
    "    result = json.loads(rec.FinalResult())\n",
    "    result_text = result[\"text\"]\n",
    "\n",
    "    end_time = time.time()  # Record end time\n",
    "    latency = end_time - start_time  # Calculate latency\n",
    "    \n",
    "    return result_text, latency\n",
    "\n",
    "# function to capture audio from microphone with a duration limit\n",
    "def capture_audio(duration, rate=16000, chunk=2048):\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=rate, input=True, frames_per_buffer=chunk)\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    return b\"\".join(frames)\n",
    "\n",
    "# main function to continuously capture and recognize live audio\n",
    "def main():\n",
    "    while True:\n",
    "        duration = 10  # duration in seconds\n",
    "        audio_data = capture_audio(duration)\n",
    "\n",
    "        # recognize the captured audio\n",
    "        text, latency = recognize_audio(audio_data)\n",
    "        print(f\"Recognized: {text} (Latency: {latency:.2f} seconds)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Chunk Size: Changing the chunk size can affect the performance of speech recognition. A smaller chunk size might lead to more frequent updates to the recognizer but could increase processing overhead. Conversely, a larger chunk size might reduce processing overhead but could delay recognition. You can experiment with different chunk sizes to see what works best for your model and environment.\n",
    "\n",
    "    Sample Rate: The sample rate determines how many data points per second are used to represent the audio. Higher sample rates can capture more detail but also require more processing power. Lower sample rates may reduce detail but can be more computationally efficient. Generally, 16000 Hz is a common sample rate for speech recognition tasks. You can try experimenting with different sample rates to see if it improves recognition performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 1024, Sample Rate: 16000\n",
      "Listening...\n",
      "Recognized: hello this is coming from mom but rajesh basic olivia for mom but for now firmly world comment on the edge (Latency: 2.41 seconds)\n",
      "Chunk Size: 1024, Sample Rate: 22050\n",
      "Listening...\n",
      "Recognized: i followed the man who for your notes mom bundle (Latency: 8.98 seconds)\n",
      "Chunk Size: 1024, Sample Rate: 44100\n",
      "Listening...\n",
      "Recognized: ako (Latency: 5.59 seconds)\n",
      "Chunk Size: 2048, Sample Rate: 16000\n",
      "Listening...\n",
      "Recognized: ballet flats and that's a mate again i ask my neighbour (Latency: 5.10 seconds)\n",
      "Chunk Size: 2048, Sample Rate: 22050\n",
      "Listening...\n",
      "Recognized: the draw for more more spinoff more (Latency: 5.08 seconds)\n",
      "Chunk Size: 2048, Sample Rate: 44100\n",
      "Listening...\n",
      "Recognized:  (Latency: 3.36 seconds)\n",
      "Chunk Size: 4096, Sample Rate: 16000\n",
      "Listening...\n",
      "Recognized: mum mana mana monsieur such i also from mom but her wish their fellow before (Latency: 2.91 seconds)\n",
      "Chunk Size: 4096, Sample Rate: 22050\n",
      "Listening...\n",
      "Recognized: home home mom my mom a smirk but for lawyer or mom's powerful jewish world (Latency: 4.05 seconds)\n",
      "Chunk Size: 4096, Sample Rate: 44100\n",
      "Listening...\n",
      "Recognized:  (Latency: 3.84 seconds)\n"
     ]
    }
   ],
   "source": [
    "# function to capture audio from microphone with a duration limit\n",
    "def capture_audio(duration, rate=16000, chunk=1024):\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=rate, input=True, frames_per_buffer=chunk)\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    return b\"\".join(frames)\n",
    "\n",
    "# main function to continuously capture and recognize live audio\n",
    "def main():\n",
    "    # Try different chunk sizes and sample rates\n",
    "    chunk_sizes = [1024, 2048, 4096]  # Experiment with different chunk sizes\n",
    "    sample_rates = [16000, 22050, 44100]  # Experiment with different sample rates\n",
    "\n",
    "    for chunk_size in chunk_sizes:\n",
    "        for sample_rate in sample_rates:\n",
    "            print(f\"Chunk Size: {chunk_size}, Sample Rate: {sample_rate}\")\n",
    "            duration = 10  # duration in seconds\n",
    "            audio_data = capture_audio(duration, rate=sample_rate, chunk=chunk_size)\n",
    "\n",
    "            # recognize the captured audio\n",
    "            text, latency = recognize_audio(audio_data)\n",
    "            print(f\"Recognized: {text} (Latency: {latency:.2f} seconds)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognized (Translated): హలో (Latency: 1.10 seconds)\n",
      "Listening...\n",
      "Recognized (Translated): నేను ఊహిస్తున్నాను (Latency: 0.88 seconds)\n",
      "Listening...\n",
      "Recognized (Translated):  (Latency: 0.41 seconds)\n",
      "Listening...\n",
      "Recognized (Translated): ప్రతి మూట మాత్రమే ఉన్నాయి (Latency: 1.30 seconds)\n",
      "Listening...\n",
      "Recognized (Translated): మా ఒక్కడి పట్ల నా కుమార్తె సరైనది (Latency: 1.65 seconds)\n",
      "Listening...\n",
      "Recognized (Translated): మీకు పని చేసే పరపతి బాగా తెలుసు (Latency: 0.82 seconds)\n",
      "Listening...\n",
      "Recognized (Translated):  (Latency: 0.41 seconds)\n",
      "Listening...\n",
      "Recognized (Translated):  (Latency: 0.64 seconds)\n",
      "Listening...\n",
      "Recognized (Translated):  (Latency: 0.33 seconds)\n",
      "Listening...\n",
      "Recognized (Translated):  (Latency: 0.38 seconds)\n",
      "Listening...\n",
      "Recognized (Translated):  (Latency: 0.41 seconds)\n",
      "Listening...\n",
      "Recognized (Translated): నాకు కావాలి (Latency: 0.46 seconds)\n",
      "Listening...\n",
      "Recognized (Translated):  (Latency: 0.35 seconds)\n",
      "Listening...\n",
      "Recognized (Translated):  (Latency: 0.37 seconds)\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecognized (Translated): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Latency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatency\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 62\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Duration in seconds\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mcapture_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# recognize the captured audio\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     text, latency \u001b[38;5;241m=\u001b[39m recognize_audio(audio_data)\n",
      "Cell \u001b[1;32mIn[20], line 49\u001b[0m, in \u001b[0;36mcapture_audio\u001b[1;34m(duration, rate, chunk)\u001b[0m\n\u001b[0;32m     47\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(rate \u001b[38;5;241m/\u001b[39m chunk \u001b[38;5;241m*\u001b[39m duration)):\n\u001b[1;32m---> 49\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m     52\u001b[0m stream\u001b[38;5;241m.\u001b[39mstop_stream()\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\vosk\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for using google transcriber\n",
    "#with latency\n",
    "\n",
    "\n",
    "import os\n",
    "import pyaudio\n",
    "import vosk\n",
    "import json\n",
    "import time\n",
    "from googletrans import Translator\n",
    "\n",
    "# Set the path to the Vosk model\n",
    "MODEL_PATH = r\"C:\\Users\\poppo\\Desktop\\downloads firefox\\vosk models\\vosk-model-small-en-us-0.15\"\n",
    "\n",
    "# Initialize the Vosk model\n",
    "vosk.SetLogLevel(-1)\n",
    "model = vosk.Model(MODEL_PATH)\n",
    "rec = vosk.KaldiRecognizer(model, 16000)\n",
    "\n",
    "# initialize Google Translator\n",
    "translator = Translator()\n",
    "\n",
    "# function to recognize speech from audio\n",
    "def recognize_audio(audio):\n",
    "    start_time = time.time()  # Record start time\n",
    "\n",
    "    rec.AcceptWaveform(audio)\n",
    "\n",
    "    # getting the recognized text\n",
    "    result = json.loads(rec.FinalResult())\n",
    "    result_text = result[\"text\"]\n",
    "\n",
    "    # translate the recognized text to English\n",
    "    translated_text = translator.translate(result_text, dest='te').text\n",
    "\n",
    "    end_time = time.time()  # Record end time\n",
    "    latency = end_time - start_time  # Calculate latency\n",
    "    \n",
    "    return translated_text, latency\n",
    "\n",
    "# function to capture audio from microphone with a duration limit\n",
    "def capture_audio(duration, rate=20000, chunk=1024):\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=rate, input=True, frames_per_buffer=chunk)\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    return b\"\".join(frames)\n",
    "\n",
    "# main function to continuously capture and recognize live audio\n",
    "def main():\n",
    "    while True:\n",
    "        duration = 3  # Duration in seconds\n",
    "        audio_data = capture_audio(duration)\n",
    "\n",
    "        # recognize the captured audio\n",
    "        text, latency = recognize_audio(audio_data)\n",
    "        print(f\"Recognized (Translated): {text} (Latency: {latency:.2f} seconds)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vosk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
